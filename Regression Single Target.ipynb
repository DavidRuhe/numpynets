{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_boston(return_X_y=True)\n",
    "y = y[..., np.newaxis]\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.w = np.random.randn(in_dim, out_dim)\n",
    "        self.b = np.zeros(out_dim)\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return np.matmul(x, self.w) + self.b\n",
    "    \n",
    "    def backward(self, d, x):\n",
    "        self.dw = np.matmul(x.T, d)\n",
    "        assert self.dw.shape == self.w.shape\n",
    "        self.db = d\n",
    "        \n",
    "    def step(self, lr):\n",
    "        self.w = self.w - lr * self.dw\n",
    "        self.b = self.b - lr * self.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanSquaredError:\n",
    "    def __init__(self, average=True): \n",
    "        self.average = average\n",
    "    def forward(self, y_, y):\n",
    "        assert y_.shape == y.shape\n",
    "        l = np.sum(np.square(y - y_))\n",
    "        if self.average:\n",
    "            l /= len(y)\n",
    "        return y_, l\n",
    "    \n",
    "    def backward(self, y_, y, average=True):\n",
    "        d = -(y - y_)\n",
    "        if average:\n",
    "            d /= len(d)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self):\n",
    "        self.linear = Linear(13, 1)\n",
    "        self.loss = MeanSquaredError()\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        x = self.linear.forward(x)\n",
    "        loss = self.loss.forward(x, y)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, x, y_, y):\n",
    "        d = self.loss.backward(y_, y)\n",
    "        self.linear.backward(d, x)\n",
    "    \n",
    "    def step(self, lr):\n",
    "        self.linear.step(lr)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598.2644557485823 loss\n",
      "356.6903118095874 loss\n",
      "240.2240306088219 loss\n",
      "161.78624192742723 loss\n",
      "108.95990717774201 loss\n",
      "73.38239167152246 loss\n",
      "49.421622566623775 loss\n",
      "33.28450765206767 loss\n",
      "22.41647263092349 loss\n",
      "15.097061085166011 loss\n",
      "10.167578867641158 loss\n",
      "6.847667863732856 loss\n",
      "4.611771964831397 loss\n",
      "3.1059392889436683 loss\n",
      "2.0917900841952357 loss\n",
      "1.4087801947428438 loss\n",
      "0.9487862343812692 loss\n",
      "0.6389891921469759 loss\n",
      "0.4303468714919955 loss\n",
      "0.2898303008548327 loss\n",
      "0.19519510622297465 loss\n",
      "0.13146013160467193 loss\n",
      "0.0885358579726717 loss\n",
      "0.05962718925711492 loss\n",
      "0.04015775958031801 loss\n",
      "0.027045474968757453 loss\n",
      "0.01821460469732361 loss\n",
      "0.012267184239250077 loss\n",
      "0.008261711503507171 loss\n",
      "0.005564103027717214 loss\n",
      "0.0037473158545794296 loss\n",
      "0.0025237448055923485 loss\n",
      "0.0016996933514347144 loss\n",
      "0.0011447106230827564 loss\n",
      "0.0007709404814065365 loss\n",
      "0.0005192135146528078 loss\n",
      "0.00034968026754326906 loss\n",
      "0.00023550290209781478 loss\n",
      "0.00015860665311815623 loss\n",
      "0.00010681851556497849 loss\n",
      "7.194020580593873e-05 loss\n",
      "4.845033825858569e-05 loss\n",
      "3.263036644212097e-05 loss\n",
      "2.1975921168254755e-05 loss\n",
      "1.4800358189375538e-05 loss\n",
      "9.96775520156118e-06 loss\n",
      "6.71309048651654e-06 loss\n",
      "4.521136702174655e-06 loss\n",
      "3.0448981912172535e-06 loss\n",
      "2.050680084590339e-06 loss\n",
      "1.381093404522068e-06 loss\n",
      "9.301397162492004e-07 loss\n",
      "6.264311225600642e-07 loss\n",
      "4.218892543307634e-07 loss\n",
      "2.8413425915457825e-07 loss\n",
      "1.9135893222031407e-07 loss\n",
      "1.2887654255324894e-07 loss\n",
      "8.679586067766425e-08 loss\n",
      "5.8455334706355204e-08 loss\n",
      "3.936853818865945e-08 loss\n",
      "2.651394961498137e-08 loss\n",
      "1.7856632644038948e-08 loss\n",
      "1.2026096979633029e-08 loss\n",
      "8.099343893333014e-09 loss\n",
      "5.454751580182427e-09 loss\n",
      "3.6736697678680104e-09 loss\n",
      "2.4741455893521838e-09 loss\n",
      "1.666289237889317e-09 loss\n",
      "1.1222135981574489e-09 loss\n",
      "7.55789169880837e-10 loss\n",
      "5.090093992568409e-10 loss\n",
      "3.42807993091716e-10 loss\n",
      "2.3087455809871313e-10 loss\n",
      "1.5548955289925627e-10 loss\n",
      "1.0471920877833123e-10 loss\n",
      "7.052636323034453e-11 loss\n",
      "4.749814263866909e-11 loss\n",
      "3.19890810921282e-11 loss\n",
      "2.1544027874932566e-11 loss\n",
      "1.4509486388767956e-11 loss\n",
      "9.771858651551863e-12 loss\n",
      "6.581157955797939e-12 loss\n",
      "4.432282687246148e-12 loss\n",
      "2.9850567344971384e-12 loss\n",
      "2.010378026948537e-12 loss\n",
      "1.3539507437565463e-12 loss\n",
      "9.118596556574282e-13 loss\n",
      "6.141198524893572e-13 loss\n",
      "4.1359784936527085e-13 loss\n",
      "2.7855015729699093e-13 loss\n",
      "1.8759814734078028e-13 loss\n",
      "1.2634372603952897e-13 loss\n",
      "8.509005718095659e-14 loss\n",
      "5.730650814308147e-14 loss\n",
      "3.859482552939778e-14 loss\n",
      "2.5992869664958113e-14 loss\n",
      "1.7505695037573576e-14 loss\n",
      "1.1789747201356769e-14 loss\n",
      "7.940166739767323e-15 loss\n",
      "5.347548433872849e-15 loss\n"
     ]
    }
   ],
   "source": [
    "for i in range(100000):\n",
    "    y_, loss = linreg.forward(X, y)\n",
    "    if i % 1000 == 0:\n",
    "        print(loss, 'loss')\n",
    "    linreg.backward(X, y_, y)\n",
    "    linreg.step(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
