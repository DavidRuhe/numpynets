{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True)\n",
    "y = np.eye(10)[y].astype(np.float32)\n",
    "X = StandardScaler().fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_n = X.copy()[:, None, :]\n",
    "t_n = y.copy()[:, None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, n_in, n_out):\n",
    "        self.w = np.random.randn(n_in, n_out) * 0.1\n",
    "#         self.w = np.linspace(-0.5, 1, n_in * n_out).reshape([n_in, n_out])\n",
    "        self.b = np.zeros([n_out])\n",
    "        \n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "        \n",
    "        self.x = None\n",
    "        \n",
    "        self.out_shape = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        assert len(x.shape) == 3\n",
    "        assert len(self.w.shape) == 2\n",
    "        assert len(self.b.shape) == 1\n",
    "\n",
    "        self.x = x\n",
    "        y = x @ self.w + self.b\n",
    "        self.out_shape = y.shape\n",
    "        return y\n",
    "    \n",
    "    def backward(self, d):\n",
    "        assert d.shape == self.out_shape, (d.shape, self.out_shape)\n",
    "        \n",
    "        self.db = np.sum(d, axis=(0, 1))\n",
    "        assert self.db.shape == self.b.shape\n",
    "        \n",
    "        d_dw = np.zeros([*d.shape, *self.w.shape])\n",
    "        \n",
    "        for i in range(d.shape[1]):\n",
    "            for j in range(d.shape[2]):\n",
    "                d_dw[:, i, j, :, j] = self.x[:, i, :]\n",
    "        \n",
    "        self.dw = np.tensordot(d, d_dw, axes=3)\n",
    "        assert self.dw.shape == self.w.shape\n",
    "        \n",
    "        d_dx = np.zeros([*d.shape, *self.x.shape[1:]])\n",
    "        for i in range(d.shape[1]):\n",
    "            for j in range(d.shape[2]):\n",
    "                d_dx[:, i, j, i, :] = self.w[:, j]\n",
    "\n",
    "        d = np.tensordot(d, d_dx, axes=([1, 2], [1, 2])).sum(1) / len(d)\n",
    "        assert d.shape == self.x.shape\n",
    "        return d\n",
    "\n",
    "    def step(self, lr):\n",
    "        self.w = self.w - lr * self.dw\n",
    "        self.b = self.b - lr * self.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.a = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        assert len(x.shape) == 3\n",
    "        x = x - np.max(x, axis=-1, keepdims=True)\n",
    "        self.a = np.exp(x) / np.sum(np.exp(x), keepdims=True, axis=-1)\n",
    "        return self.a\n",
    "    def backward(self, d):\n",
    "        \n",
    "        diag = np.stack([np.diag(self.a[i, 0]) for i in range(len(self.a))])\n",
    "        op = np.stack([np.outer(self.a[i, 0], self.a[i, 0]) for i in range(len(self.a))])\n",
    "        J = diag - op\n",
    "        \n",
    "        return d @ J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy:\n",
    "    def forward(self, y_, y):\n",
    "        self.y_ = y_\n",
    "        self.y = y\n",
    "        \n",
    "        assert y_.shape == y.shape\n",
    "        \n",
    "        l = - np.sum(y * np.log(y_))\n",
    "        l /= len(y)\n",
    "        return y_, l\n",
    "    \n",
    "    def backward(self):\n",
    "        y_ = self.y_\n",
    "        y = self.y\n",
    "        \n",
    "        assert y_.shape == y.shape\n",
    "        d = (- y / y_) / len(y_)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRes:\n",
    "    def __init__(self):\n",
    "        self.linear1 = Linear(64, 10)\n",
    "        self.softmax = Softmax()\n",
    "        self.loss = CrossEntropy()\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        x = self.linear1.forward(x)\n",
    "        x = self.softmax.forward(x)\n",
    "        loss = self.loss.forward(x, y)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self):\n",
    "        d = self.loss.backward()\n",
    "        d = self.softmax.backward(d)\n",
    "        d = self.linear1.backward(d)\n",
    "\n",
    "    \n",
    "    def step(self, lr):\n",
    "        self.linear1.step(lr)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logres = LogRes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 2.3302958458204133\n",
      "Accuracy: 0.203125\n",
      "Loss 1.073794456521439\n",
      "Accuracy: 0.7578125\n",
      "Loss 0.7385588104587009\n",
      "Accuracy: 0.8046875\n",
      "Loss 0.5932505963822458\n",
      "Accuracy: 0.8515625\n",
      "Loss 0.5090887035252033\n",
      "Accuracy: 0.859375\n",
      "Loss 0.4517124208825424\n",
      "Accuracy: 0.859375\n",
      "Loss 0.40880502030840693\n",
      "Accuracy: 0.8671875\n",
      "Loss 0.37494774953357685\n",
      "Accuracy: 0.875\n",
      "Loss 0.34734898134110387\n",
      "Accuracy: 0.8828125\n",
      "Loss 0.32436836741969566\n",
      "Accuracy: 0.921875\n",
      "Loss 0.3049368510900545\n",
      "Accuracy: 0.921875\n",
      "Loss 0.28830406221782023\n",
      "Accuracy: 0.921875\n",
      "Loss 0.2739169655905265\n",
      "Accuracy: 0.9296875\n",
      "Loss 0.2613552531902281\n",
      "Accuracy: 0.9453125\n",
      "Loss 0.2502932033904006\n",
      "Accuracy: 0.9453125\n",
      "Loss 0.24047501919723024\n",
      "Accuracy: 0.9453125\n"
     ]
    }
   ],
   "source": [
    "for i in range(16):\n",
    "    for j in range(0, len(x_n), batch_size):\n",
    "        x_batch = x_n[j: j + batch_size]\n",
    "        t_batch = t_n[j: j + batch_size]\n",
    "        y_batch, loss = logres.forward(x_batch, t_batch)\n",
    "        logres.backward()\n",
    "        logres.step(lr=0.1)\n",
    "        if i % 1 == 0 and j == 0:\n",
    "#             print(j)\n",
    "            print('Loss', loss)\n",
    "            print('Accuracy:', (np.argmax(y_batch, axis=-1) == np.argmax(t_batch, axis=-1)).sum() / len(y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
